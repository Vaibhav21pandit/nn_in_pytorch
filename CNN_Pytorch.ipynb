{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP0VZ6OtWrLhf1Swcsrfaxz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vaibhav21pandit/nn_in_pytorch/blob/main/CNN_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6-Mb3FbqNZR"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import Dataset,DataLoader"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzdKocyZH2x1"
      },
      "source": [
        "LeNet Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK8aEeR9qbJe"
      },
      "source": [
        "#Defining the LeNet architecture\n",
        "class LeNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNet,self).__init__()\n",
        "    self.pool=nn.AvgPool2d(kernel_size=(2,2),stride=(2,2))\n",
        "    self.conv1=nn.Conv2d(in_channels=3,out_channels=6,kernel_size=(5,5),stride=(1,1),padding=(0,0))\n",
        "    self.conv2=nn.Conv2d(in_channels=6,out_channels=16,kernel_size=(5,5),stride=(1,1),padding=(0,0))\n",
        "    self.conv3=nn.Conv2d(in_channels=16,out_channels=120,kernel_size=(5,5),stride=(1,1),padding=(0,0))\n",
        "    self.fc1=nn.Linear(in_features=120,out_features=84)\n",
        "    self.fc2=nn.Linear(in_features=84,out_features=10)\n",
        "\n",
        "  def forward(self,input_image):\n",
        "    x=torch.relu(self.conv1(input_image))\n",
        "    x=self.pool(x)\n",
        "    x=torch.relu(self.conv2(x))\n",
        "    x=self.pool(x)\n",
        "    x=torch.relu(self.conv3(x))\n",
        "    x=x.reshape(x.shape[0],-1)\n",
        "    x=torch.relu(self.fc1(x))\n",
        "    x=self.fc2(x)\n",
        "    return x\n",
        "\n",
        "model=LeNet()\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vwzy6_NE12Yv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f0eb20d-8a40-4e72-9a1c-75732dda5665"
      },
      "source": [
        "input=torch.rand((1,3,32,32)) #generating noise of size 32x32\n",
        "print(model(input).shape) #using the generated noise for a forward pass to see if the model output is correct "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGouLcJzH7Zg"
      },
      "source": [
        "VGGNet Implementation \\\n",
        "Paper- https://arxiv.org/abs/1409.1556"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSufGaZQHuYm"
      },
      "source": [
        "#VGG architecture\n",
        "\n",
        "class VGGNet(nn.Module):\n",
        "  def __init__(self,input_channels):\n",
        "    super(VGGNet,self).__init__()\n",
        "    self.in_channels=input_channels\n",
        "    self.layers=[64,64,\"M\",128,128,\"M\",256,256,256,\"M\",512,512,512,\"M\",512,512,512,\"M\"]\n",
        "    self.conv_layers=self.conv_layer_creator(self.layers)\n",
        "    self.fc_seq=nn.Sequential(\n",
        "         nn.Linear(in_features=(512*7*7),out_features=4096),\n",
        "         nn.ReLU(),\n",
        "         nn.Linear(in_features=4096,out_features=4096),\n",
        "         nn.ReLU(),\n",
        "         nn.Linear(in_features=4096,out_features=1000)\n",
        "    )\n",
        "\n",
        "  \n",
        "  def forward(self,input_image):\n",
        "    x=self.conv_layers(input_image)\n",
        "    print(x.shape)\n",
        "    print(self.conv_layers)\n",
        "    # x=nn.Flatten(x)\n",
        "    x=x.reshape(x.shape[0],-1)\n",
        "    x=self.fc_seq(x)\n",
        "    return x\n",
        "\n",
        "  def conv_layer_creator(self,layers):\n",
        "    conv_layers=[]\n",
        "    in_channels=self.in_channels\n",
        "    for i in layers:\n",
        "      if i==\"M\":\n",
        "        conv_layers.append(nn.MaxPool2d(kernel_size=(2,2),stride=(2,2)))\n",
        "      else:\n",
        "        #note the padding factor of 1\n",
        "        conv_layers.append(nn.Conv2d(in_channels=in_channels,out_channels=i,kernel_size=(3,3),stride=(1,1),padding=(1,1)))\n",
        "        # A BatchNorm can be added but not implemented in the original paper\n",
        "        conv_layers.append(nn.ReLU())\n",
        "        in_channels=i\n",
        "    return nn.Sequential(*conv_layers)\n",
        "\n",
        "model=VGGNet(3)\n",
        "\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmUmW9lYSr26",
        "outputId": "205d3fdb-c476-47b1-92be-56f3a2bf8309"
      },
      "source": [
        "input_image=torch.rand((1,3,224,224))\n",
        "print(model(input_image).shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 512, 7, 7])\n",
            "Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU()\n",
            "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (3): ReLU()\n",
            "  (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (6): ReLU()\n",
            "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): ReLU()\n",
            "  (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (11): ReLU()\n",
            "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): ReLU()\n",
            "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (15): ReLU()\n",
            "  (16): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (18): ReLU()\n",
            "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (20): ReLU()\n",
            "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (22): ReLU()\n",
            "  (23): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (25): ReLU()\n",
            "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (27): ReLU()\n",
            "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (29): ReLU()\n",
            "  (30): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            ")\n",
            "torch.Size([1, 1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5WCARQxatN-"
      },
      "source": [
        "**Debugging** \\\n",
        "Forgot to add padding in the Conv2d module and was getting error so the following cell shows how to debug a neural net when shapes dont match"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IXQhLd5Uyff",
        "outputId": "cd627905-26fa-445a-af63-8c3f7de31afc"
      },
      "source": [
        "#This is how to debug a model\n",
        "layers=[64,64,\"M\",128,128,\"M\",256,256,256,\"M\",512,512,512,\"M\",512]\n",
        "def conv_layer_creator(layers):\n",
        "  conv_layers=[]\n",
        "  in_channels=3\n",
        "  for i in layers:\n",
        "    if i==\"M\":\n",
        "      conv_layers.append(nn.MaxPool2d(kernel_size=(2,2),stride=(2,2)))\n",
        "    else:\n",
        "      conv_layers.append(nn.Conv2d(in_channels=in_channels,out_channels=i,kernel_size=(3,3),stride=(1,1)))\n",
        "      # A BatchNorm can be added but not implemented in the original paper\n",
        "      conv_layers.append(nn.ReLU())\n",
        "      in_channels=i\n",
        "  return nn.Sequential(*conv_layers)\n",
        "conv_layers=conv_layer_creator(layers)\n",
        "print(conv_layers(input_image).shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 512, 6, 6])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qgDOlLCdWHI"
      },
      "source": [
        "Implementing AlexNet \\\n",
        "Paper-https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ubaDKL9W2KL"
      },
      "source": [
        "class AlexNet(nn.Module):\n",
        "  def __init__(self,in_channels):\n",
        "    super(AlexNet,self).__init__()\n",
        "    self.in_channels=in_channels\n",
        "    self.conv1=nn.Conv2d(in_channels=3,out_channels=96,kernel_size=(11,11),stride=(4,4))\n",
        "    self.pool=nn.MaxPool2d((5,5),stride=(2,2))\n",
        "    self.conv2=nn.Conv2d(in_channels=96,out_channels=,kernel=(5,5),)\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw_R-l-EfwwR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mbJjP3afwtb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}